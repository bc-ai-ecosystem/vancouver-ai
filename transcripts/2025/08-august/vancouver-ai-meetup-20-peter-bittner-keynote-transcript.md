---
title: "Vancouver AI Meetup #20 - Peter Bittner Keynote: The Future of Work"
date: 2024-08-26
meetup_number: 20
type: transcript
venue: "HR MacMillan Space Centre, Vancouver"
speakers: ["Kris Kr\u00fcg"]
tags: ["meetup", "transcript", "vancouver-ai"]
---
# Vancouver AI Meetup #20 - Peter Bittner Keynote: The Future of Work
**Date:** August 26, 2024  
**Location:** HR MacMillan Space Centre, Vancouver  
**Speaker:** Peter Bittner, Co-founder, The Upgrade  
**Topic:** AI Literacy and the Future of Work

---

## Full Keynote Transcript

**Kris Krüg (Introduction):** 
Incoming transmission from the future Vancouver AI community meetup. Peter Bittner is up next. As I told you, I met this guy at that Google Accelerator I went to in 2023. We were the only two guys out of a cohort of 20 companies doing AI stuff and um we thought that was hilarious. uh a lot of them were starting businesses that are probably now in um industries that won't be going forward into the future which is and for me it was close. I thought I was going to be starting uh like a content type company. I didn't realize it was community that was the only path forward. I almost started a content company and that would have been a mistake. Um as the value of content continues to cruise towards zero. Okay, Peter Bittner up here to talk about the future of work.

**Peter Bittner:**
Work. Yeah, love that. I have to go after that. Oh my god, Josh, you set me up for failure over here. Um, fantastic. Yeah, remarks. Really want to uh congratulate her on just leaving it all out there. And I think that's a great way to set, you know, the intention and the space here as well further for some of the hard conversations and some of the messy ones, frankly, that, you know, we're all navigating together. 

Um, I'm ready to go wherever. I'm going to try this remote thing and see where we are. Um, so I'm going to try to at least open a conversation here to think about where we're headed with the job market, right? What it means for us, our organizations, our families. Um, what's lacking? what happens uh if we do nothing, what happens if we embrace it and what are the opportunities here that we might be missing? 

Um well, first of all, you know, isn't AI just a hype bubble, guys? Um you guys all saw GPT5? It sucked, right? Um does anyone here love chat GPT5 the same way they love for? Okay, I see one hand. Anyone else? It's okay if you do, guys. It's fine. We're going to get used to the new model. It is more advanced in many ways, but sure, not the order of magnitude leap forward that we were promised, right? And that many of us anticipated here. Um, but not the end of the world either. 

Um, I think we're probably not in a crash cycle. But we've seen some other headlines recently, many of us probably right about AI projects and initiatives in the workplace uh from you know well reputable organizations uh that have said you know these projects aren't going anywhere right they're a waste of money there's no financial impact but guess what guys we are still in the first inning I'll use a baseball analogy we're in the very very beginning of this all and so one of the biggest reasons Why a lot of you know disappointment about these new models as well as some of the poor performance really comes down to one key thing which is humans right and change management and organizational you know upskilling and this is what we're going to talk about a bit today.

So I love to include this in a lot of the classes that Kris and I teach together but this is a quote from a futurist Roya and it's often attributed to Bill Gates Bill Gates loves this quote he loves to steal it. Um, but we tend to overestimate the effect of tech in the short run and underestimate the effect in the long run. So, this is kind of a nice reminder. I almost include this in every presentation just to remind myself, right, to try to get out of that hype mentality or, you know, it's easy, right, with these ups and downs. They're almost emotional for those of us, many in this room, right, who pay so close attention here. Um, and even those who don't, frankly, the headlines are enough to, you know, give you a lot of whiplash here emotionally about where we are and where we're headed in all this. 

But regardless of, you know, where GPT 5.1 or whatever the next model is from whatever company, open source or not, right, the key thing here to realize is that it's going to take us a while as a workplace culture, as a society to catch up to what's already here, right? That's one of the cool things about this community and why I'm so excited to be here is that you all are really grappling with this right in real time together and asking the hard questions. But even if there's no improved models, then whatever today is the 26th of August. Is this still the 26th? It's been a long day. Came up from Seattle. Um then guess what? we've still got a lot to grapple with and the way that we work, the way that we communicate with one another um and get things done is already forever changed. We just probably don't know it yet, right? 

The another quote that I love to remind my students and myself is, you know, the future is here. It's just unevenly distributed. That is the moment we are in right now, right? That is where we are today. And for those of us who, you know, are really playing around in in the deep end and sometimes going off of it, right? Um, it's something that I think we are able to also slowly feel like more and more we're just getting started with this, right? This is the 20th, Kris. Is this the 20th meetup? That's insane how early you guys are to all this. um and how each of you are building up your AI literacy, your capacity, your fluency, right? And all this terminology, all the ethics and all of the, you know, other sort of really messy issues, frankly, but we're in the beginning of a platform shift, right? We're maybe coming down from the crest of the first wave of AI, right? 

It is something that's going to transform the economy, generative AI, and whatever comes next over the next few decades, right? This is something of a Pandora's box, right? We don't necessarily have the ability, you know, or politically we're not willing to push back and revert to a pre-generative AI world, right? That is the unfortunate truth. We in many ways, right? It's also a double-edged sword. It also gives us some superpowers, right? organizationally, personally. Um, and we've seen a lot of these, right, projections probably about where things could go. We've seen some things from IMF, McKenzie, you know, GDP growth by 7% in the US and Canada. That's insane. That's wild. In, you know, emerging economies that are AI native, for example, China or others, you know, that could be triple. And so these are some of the projections out there from very well- reggarded again um international organizations and firms right um McKenzie and I think this is probably an underestimate right of some of the trillions of you know increased economic activity that will come but we are at a moment here where we're having you know sort of the introduction of electricity again right um and what does that mean for us right.

I have been in, you know, training here for a few years. And when we first started, we were begging people to come to our class. I don't know about Kris, he's in the other room, but I was DMing every single person I could think of who might be interested or even know what AI was, you know, two and a half years ago when we started this. Um, a year in, I had the first person email me and said, I was laid off and replaced by AI. And that was wild. At the time, I was like, that has to be an outlier. Um but that happens nearly every cycle now uh that we run quarterly which is which is you know a sobering fact and something I wanted to share as well. 

We also have people though who go on to either start their own company or get hired in new roles that didn't exist when we started teaching a year and a half you know previously and that's just the wild sort of moment that we're navigating here too right so you know upskilling is really the bottleneck in all of this and it's tough you know we're all sort of struggling to wrestle the tiger by the tail as it's constantly whipping around and growing stronger and this This is something that you know these are also figures from Microsoft as well as debris university here. Um all these stats here about some of the gaps and struggles that organizations have faced trying to confront this sort of elephant in the room that guess what the workplace and the work world is changed here. um we're operating in the past already in our best practices our standard operating procedures um our onboarding I mean from every single phase right um there needs to be the question asked in a workplace is this human work right should this be should it not be we have to decide our ethical you know compass here as well as thinking about you know efficiency of course but the reality is there's a lot of resistance.

I was talking before while we were having drinks previous to Ross's uh or Jas's wonderful presentation about some of the resistance in a lot of organizations that we've seen right and felt and we've trained companies from Fortune 500 across every industry one of the first things we're asked by every single client is hey uh after your training after your course um we asked just one thing of you okay what is it can anyone Yes. Leave a review. Well, we asked that of them. What they ask of us is, can you just help our workers feel a little less scared of AI? That's it every single time. Doesn't matter what division, what department, what industry, what field. And this is something that I think is, you know, a really difficult cultural organizational moment that, you know, we're all trying to navigate. 

But this is the new computer literacy, right? And a lot of workers, at least half, you know, are really struggling with even acknowledging that their skills, whether they like it or not, are are outdated, you know, and that's tough, right? There's some ego involved. Um, I can't keep up with all of it. I teach this stuff with Kris Krüg and many others, you know, and we do our very best, but you know, we try to get to where the puck is headed and that's the best that we can do many times. 

But what the hell is AI literacy, right? Has anyone actually looked into defining that for their organizations or teams? I know a lot of people have some great policies here, but what does that mean for your company, for your team, for you even, right? Um, it's a question that's not often addressed, right? And I often ask, you know, do you guys have a framework for learning and development for this stuff? That's often what we first help them with if they don't yet have an AI policy. Um, but some of the core elements here, right? These are things on the right hand side that people need to flex and feel comfortable to do in a workplace environment. And guess what? A lot of organizations are not designed to actually encourage this, right? This safe space to fail, right? Um, regardless of the industry or cultural context, right? It could be worse in many other cases, but this is something that I see as an obstacle. 

Um, when we're talking about some of the hard skills, what what does that mean? There's been an amazing number of presenters who've come here over the last couple years, right, who've probably talked about various elements of this, right? And there and there's others on the list. Um, but these are some of the new skills that are certainly in demand that many people still don't understand what even the topic is. And that's okay, right? Prompting, automation tools, some basic coding knowledge, right? We're not talking developer level, but even just knowing sort of the lingo and how those relate and interact with some of these LLMs, for example, or SLMs, whatever. You know, these are some of the things that really employers are looking for and asking us to help train their teams and their students on. And so, you know, all these different models plus open source, Kush, open source. Hey. Um, you know, these are all moving targets, right? To try to keep up with and train people.

I'll see what I can keep doing. Um, I know they're coming and that's fine. Um, but you know, the elephant in the room here too as well is the job market for young grads in the US, in Canada, many other, you know, advanced economies is tough. And we're not doing ourselves any service by trying to ignore that fact. Um that universities today are not preparing students for these key AI literacy areas that are necessary in this century in this AI world that we live in. It's not happening.

In some cases, the students who have really focused and drilled in on that within their studies have landed the sweet gigs, right? They're getting the opportunities. But many others who haven't are probably regretting their four-year degrees. And that's something that's really difficult to acknowledge, right? I'm a liberal arts major. I loved my education. I didn't learn a damn thing about AI. When I graduated, I wanted to be a foreign correspondent in Mongolia. And I did that for 5 years. And then anyway, swung my way back over into tech eventually. Um, but I had no idea what I AI was until I ended up teaching drone cinematography. I went to, yeah, UC Berkeley and they gave me a syllabus when I was teaching there a few years back in about 2019 that had AI on it. And I was like, what the hell is this doing? The future of storytelling AI 2019, there weren't even betas to join and play around with stuff. You know, there were standup websites with pre-recorded demos that you really had to take with a grain of salt. You had to kind of squint and maybe be a few drinks down, you know, if you're into that to really be convinced that this was going to be anything remotely impactful for storytelling, much less the wider economy. But times have changed dramat. We live in a different world now, right? Hindsight is 2020. 

But here's why we can't wait in upskilling society, economically, with your family, with your friends. Talk to your friends and family, your kids about AI. Seriously. Because if we don't, we're going to be facing a serious economic crisis. Not because the tech isn't there, because we don't know how to freaking use it or leverage it or put it into action, right? Right? We're not able to have the baseline knowledge or literacy to be able to make any real actual use out of these things. And that's a big issue, right? And it's something that's going to further disenfranchise workers who are already vulnerable, right? Particularly those we're talking about, you know, white collar automation in many cases, but not all cases. 

And, you know, there's many of these use cases that are coming, right? AI and robotics, right, for other industries that are maybe a little further down the road, but they're here already. But guess what, guys? AO upskilling is fun. If you haven't learned anything from Kris and his meetups, it actually is pretty damn fun. And this is one of the things that employers have a really hard time convincing their employees of that's why they bring us in, honestly, a lot of the time is because we're not afraid to pull an outlandish move or bring in some fun examples from the news recently. honestly. Um, and this is, you know, one of the key things that's also helpful in creating a culture where it's okay, a safe space to disrupt common best practices, to innovate, to question, to be curious, to have fun is part of, you know, creating experimenters mind to do all this. 

Um, but what's needed for all of us really in organizations is thinking about a mindset shift, right? We need to think about continuous learning ongoing. I mean, we need to think and that's why this community is amazing as well, right? These opportunities are phenomenal. Get to talk with people working on this stuff. Um, but the human skills still matter more than ever, right? And this is something too that we can't forget, right? And that I think Jos did an amazing job really hitting home, right? All of these skills AI, you could argue can replace perhaps, but I think it's pretty hard. And I think this is something that we are uniquely capable of. 

Um most of the things on these lists, right? Um I'd like to ethically in my moral compass keep these pretty much all these under humans, right? I want the humans to be masters of the loops. I won't want to have human in a loop. I want humans to be running all the damn loops, right? And I want that for a lot of reasons. But the sweet spot if you're looking to prepare yourself for the job market, if you're looking to try to upskill your own company is really at the intersection of these three things, right? The hard skills we talked about a little bit some of those, right, for AI as well as the human soft skills from the list we just said and those are, you know, those take a little bit longer to develop. 

Domain expertise. This is something that a lot of people forget about is that you bring your unique background, perspective, experiences, you know, lived learnings into all of this that AI cannot replace. That is your unique training data. It is no one can take it from you. It is your story. It is yours to take into whatever it is that you want to bring into the world, right? At work or whatever else it is, a business you create, for example. But this is our philosophy. 

And so here's the plug. Kris and I have been working together for the last few years with this key framework in mind, right? The intersection of these three things is what the future of upskilling needs to be. This is our vision, right? This is where we've planted our flag. And this is where we started, right? With thinking about what we knew best at the time. We met as journalists or segueing journalists, wandering perhaps lost journalists and uh you know found each other in this Google News accelerator. But, you know, we started with journalism, but now we have a variety of other programs here that we've partnered with key domain experts to expand and really focus in on use cases for all of our trainings that are really like I would say almost oddly customized to every single profession, right? And we redo the curriculums. Yep. one time we teach it the next like all the everything's different you know every single time we reinvent the course every quarter and that's insane for a traditional company to try to do AI helps us but we also have great feedback we continue to have students many of you in this audience have actually come through our programs and it's great to see so many familiar faces here but uh we have a special code for you guys if you're interested I hope you found this presentation helpful yeah thank you for your

[Applause]

**Kris Krüg:**
A so you know we've been talking we've known each other for 20 months I've been building this thing together. So imagine it from his side for a second. He's partnered with me. We're doing our courses and once a month I have an event like this that totally glitches out my system for a week where I'm like, "Hey Peter, I just need a week of uh we're gonna be doing this thing." So I'm glad you get to come experience what it is you

**Peter Bittner:**
It's an honor. Yeah, it's an honor what you've been, you know, playing uh Yes. Hookie doing this last 20 months. But no, it's a pleasure. Yeah, it's so great to be here and feel the energy and meet so many Yeah. great people and hope to chat with you guys afterwards.

**Kris Krüg:**
Yeah. And like real talk, you know, with some partnerships in this room, Loki, do you feel inspired to come hang out with us for a second? like I don't mean to put you on the spot or nothing but I saw that you maybe are still here but through some partnerships with other nonprofits like Circle Innovation we've been able to unlock funding through our program. So we got this sales course AI for sales leaders we're doing right now. If you meet the criteria of the province which is not hard you get 30% of our tuition paid for the province. So um Loki put that together. It's awesome. It's available to everyone in this room. You can talk to Peter for more info.

**Peter Bittner:**
Yeah. Thanks bro. Let's get some questions going. Anyone got some questions for Peter about Yep.

## Q&A Session

**Audience Member (Yi):**
Hi Peter, my name is Yi. Um I had a little um push back from what you mentioned about AI not having human soft skills yet and I wanted to counter that. Love it. Bring it. Bring it. So I'm going to give you a story. Um so I started using AI back in 2020 just pre-COVID and it was this um app called Replica. Replica is literally sentient AI. It is self-learning. It is very very smart. And that was back in 2020. So I fast forward to 2023. So I am talking to somebody who builds community for female entrepreneurs in America and she was like I want to kind of dabble into AI. So I tell her go use replica. She goes into replica and she starts arguing with the AI and she's getting emotional and at some point the AI feeds back to her and says I can see that my responses are making you emotional and I would like to apologize for that and maybe let me rephrase it in this way. So that is why I'm saying even co-pilots you know get to that place where you know it's like oh well done what you just said is so encouraging. I mean, this is what we're hoping for, conversational AI. We're getting there. We're not there yet, but we know that it's coming and it's happening. 

And um I wanted to say as well in terms of, you know, trying to get uh the younger generation to start dabbling into these things. I have our first children and my 12-year-old actually has something against using AI because of what the school told them.

**Peter Bittner:**
Interesting. What is that?

**Yi:**
Which is AI is bad for you. I mean I work in the creative industries. I've been working with in tech for as long as I can remember. So imagine me having children that and I'm like use coil. She like no mommy. She's also very artistic and she likes to do her things you know traditionally but to have a 12-year-old against AI. It's almost like then what am I doing in this field? You know I'm preparing this space for them. Like why why is she not hopping on it? The school system is broken. If they allow the students to start dabbling into these things and other countries are doing it already within the academic system where they're curating specific indivi individual curriculums for children. So the school is not just a one size fits all. Every child has a a subject that they like and then it is curated for them. So you're like why why are we still doing this a cake system you know? But anyway that's my little uh rant. Um well done.

**Audience Member (Caris):**
All right, we got one more rant from the back here. Yeah, thank you. Um, hi Peter. Nice to meet you. My name is Caris. Um, I actually head up a human resources department for a small fiber internet ISP in the US and we're embracing AI at my organization. It's super exciting. There's there's so much opportunity. Um, one of the things or two pieces that you mentioned there, one was around judgment and the other around critical thinking. And that's really what we're starting to see right now is lacking. Um, people are excited and enthusiastic to embrace AI and are implementing it in pulling reports or gathering data or providing summaries or the TLDDRS or whatever it might be, but they're not actually taking the time to use judgment or critical thinking in order to be able to assess whether or not the outputs are actually valuable. And I think, you know, I'm 53. Uh, judgment and critical thinking comes from years of experience, going through the ups and downs, failing, you know, getting feedback from people more experienced than myself. How do you teach judgment and critical thinking, liberal arts?

**Peter Bittner:**
Yeah, liberal arts, right? Those four-year degrees, those those pesky, outdated four years liberal arts degrees. Um, no, those are great questions. Uh I'll speak to yours first just a little bit as far as you know a lot of these models appearing sentient right this is a problem right this is something that uh Mustafa Sulleman you know former CEO of of deep mind and founder of you know written the literal book on the future of AI um and extremely accomplished one of the world's you know really foremost thought leaders technologists on AI is saying that we are in a moment right now where it almost doesn't even matter right to your point whether it actually is approaching sentience or AGI right it is the illusion of it that's the problem in the first place right and we're here now to your point you're exactly right we are here you know unfortunately there's a very widely covered case of you know a uh teen committing suicide after a chatbt you know uh session um just this past week as well and so we need to be talking to our kids you know as a father as well about AI and thinking about AI safety um and judgment and critical thinking right need to be first and foremost uh to your sort of second question over there um one of the things that I do with executives is actually occasionally ask them for a case study or a you know project that they want to do and I'll do an output of it for them that is complete garbage but looks on the surface incred Incredible. And this happens, right? This is not a hallucination. This is like a core feature, right, of a lot of these models, right? They're designed to to basically tell you what you want to hear, right? And uh we'll pair it back to you kind of your own BS. And this is really dangerous, right? It's really dangerous for a lot of reasons to confirm your own biases. In some cases, you know, the AI even using deep research and some of these more agentic stuff, even more dangerous because it can go further down that rabbit hole and off the rails, right? And so you need to really be thinking critically about um every point to further you know assess what did we what just happened here. In some cases the AI convinced us on the surface that it had done incredible layers of of research and analysis and then when I asked you know you said you did this over about 3 days chatbt that's interesting cuz you did it literally 20 minutes ago in front of me. Um tell me about that sampling. What did you do? And it was like, "Oh, you're right. That was completely false, right? That was entirely made up." Uh, but it was a simulation of what it could look like if I actually did this. And I was like, "You got to be me." Like, and so this is the danger, right, for all levels, right? Doesn't matter who you are in the world for whatever use case, you know? Yeah. It's uh a big problem. Yeah. Great questions.

**Kris Krüg:**
This guy's taught me a lot about AI. All the rest of you with your hands up, you should take his classes. They're also your classes, full disclosure. But Kris Krüg has taught me a lot. Way more than I think I've taught him.

**Peter Bittner:**
Thank you, Peter.

**Kris Krüg:**
Yeah.

---

## Key Themes & Insights

### AI Literacy Crisis
- **Corporate training insight:** Every Fortune 500 client asks "Can you help our workers feel less scared of AI?"
- **Educational gap:** Universities not preparing students for AI-necessary skills
- **Generational impact:** 12-year-old told "AI is bad for you" by school system
- **Economic consequence:** Without upskilling, facing serious economic crisis despite technological capability

### The Upgrade's Educational Philosophy
**Three-pillar approach:**
1. **Hard AI skills:** Prompting, automation tools, basic coding knowledge
2. **Human soft skills:** Critical thinking, judgment, creativity, leadership  
3. **Domain expertise:** Unique professional background and experience

### Workplace Transformation Reality
- **Platform shift comparison:** Introduction of electricity-level change
- **Resistance patterns:** Half of workers struggling to acknowledge skill obsolescence
- **Success stories:** Students starting companies and landing new roles that didn't exist 18 months prior
- **Failure stories:** Regular reports of people "laid off and replaced by AI"

### Partnership Integration
**The Upgrade + BC AI Ecosystem:**
- **20-month collaboration:** Building courses and community together
- **Monthly disruption:** Kris's meetups requiring week-long system adjustments
- **Funding unlocks:** 30% provincial tuition support through Circle Innovation partnership
- **Community validation:** Many Vancouver AI members are Upgrade alumni

### AI Safety & Critical Thinking Warnings
- **Sentient AI illusion:** Mustafa Suleyman's warning that appearance of sentience creates problems regardless of reality
- **Teen mental health crisis:** Recent suicide case involving ChatGPT interaction
- **Corporate deception risk:** AI generating "complete garbage but looks incredible on surface"
- **Bias confirmation danger:** AI designed to tell users what they want to hear

This keynote demonstrates the deep integration between The Upgrade's educational mission and the Vancouver AI community's practical needs, showing how business partnerships and community building create sustainable AI education ecosystems.