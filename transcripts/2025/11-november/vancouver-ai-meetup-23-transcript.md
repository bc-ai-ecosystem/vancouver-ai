# Vancouver AI Community Meetup #23 - Full Transcript

**Date:** November 26, 2025
**Location:** HR MacMillan Space Centre (Planetarium), Vancouver, BC
**Host:** [[Kris Krüg]]
**Event Number:** 23
**Theme:** Ethics Panel - "Portals Not Panels"
**Attendee Demographics:** ~60-70% first-timers, 30-40% BC AI members

---

## Opening

**[[Kris Krüg]]:** Okay, Mr. Pixel Wizard, let's go. Welcome everybody. You are at the HR MacMillan Space Center. This is the Vancouver AI Community Meetup number 23. You are the Vancouver AI community. Yeah, let's go. I'm so happy you're all here tonight. There's a lot of new faces who's here for the first time.

I wanna say that's like 60 to 70% who's here as a part of the BC AI nonprofit membership. That's the other 30 or 40%. That's pretty cool. Awesome. Well, I'm really happy that everyone's here tonight. If you've been hanging around for long enough, you know, I say brazenly on the internet: We don't do panels, we do portals.

Well tonight, what looks like a panel, I assure you, is actually a portal. I went to a talk at a sustainable film production day recently, and Catherine Warren had put together a panel about climate change, but from people who were using these tools who were interested in them, people who were studying AI and were holding it to account and had some strong opinions.

And it was a fucking rad conversation. It was unexpected. I thought you were going one way, Liz. You went another. It was awesome and the way the audience engaged afterwards and stuff. So I wanted to, we've built a special container here and I wanted to bring it in and see what happens.

We have tough talks here all the time. We examine both the opportunities and also, you know, are not afraid to critique the status quo. So anyway, I'm really happy you guys are here. That's gonna be the main payload of the evening. We also have a couple other surprises for you, but let's kick things off right around here.

Those of you who are here last month, met uncle big lungs, Counselor Anthony Joseph from the Squamish Nation. Would you just come on up and welcome us here properly, sir, it's really nice to see you. We're here on Squamish land. You guys maybe know that development right there. It's called Senakw. It's owned by the Squamish Nation. They're making major moves around here. Welcome friend.

---

## Indigenous Welcome - Anthony Joseph (Isiléyu)

**Anthony Joseph:** Yeah, all good. Great. Take care everyone.

*[Eagle feather gifted to Kris]*

Kris Krüg, Craig Kruger. Kru. Kru. Kru, sorry. Even us indigenous, we get some of your names wrong too.

I just wanted to share that. For those of you don't know me, Anthony Joseph is my English name, but Isiléyu you might have seen in the program is my K'emain, which we say is an ancestral name. And the ancestral name - just talking to Kris Krüg about our naming process to get an ancestral name - your elders would watch you and see how you carry yourself.

A lot of times, like when you would hear some of our K'emain, the end would be almost like what you did. So, like you might hear - my dear aunt Joy Justin McCullough's K'emain is "Al To Knot." To Knot is to weave. So it shows that she's a weaver, cedar weaver, wool weaver.

And then my uncle Chester, his ancestor's name is "Colossal." Tin is to like, to have a tool or usually refers to carvers. So just wanted to share that. But my name comes from my Sto:lo side. I grew up in Stawamus in the Squamish Valley.

I raised my hands to each and every one of you guys. I said which means many beautiful people. And you guys are. I thank you for come to watch and respect the work of dear, dear Kris Krüg and his family of artists. So it's a process to make art. I come from a family of artists, my Joseph family. We have a lot of artists.

Actually, when I moved back to the Squamish Valley in 2010, my Auntie Joy shared "You were good with math." Yes, I was. And she was like, "Okay, I'm gonna teach you to weave." I was like, whoa. Cedar? She is like, no, wool. So this is my first tunic that I made.

So on the front, it's a diamond design. It's centered around the middle, and then on the back it's called the chevron design. So you can see the chevron. So that was where I started. This is where I ended. It took a bit to get it, but I had my dear sister Rose and my Auntie Joy helping hold me up with that work.

But I'm also thankful. I know I talked to Kris Krüg about talking about relation to AI. It's really cool. There's so many - you could push so many boundaries. When I think about when with our ancestors, a lot of my friends, my non-indigenous friends would be like, "Hey, your uncle's using a chainsaw to carve this." Yeah. "Ancestors didn't have chainsaws." It's like, no. **But they would've used it if it was there.**

And that continues today. We're always looking for new tools. And I've had talks with some of my friends that are into doing AI art, that do indigenous art. And some of the work they come through - they find really cool tools on the AI Canva. I think one of my friends is using that.

That's actually how I created my pamphlet for when I was running for council. They're like, "Wow, where did you - who did you hire to do this?" I did it myself. I can't afford to hire an art professional, you know, much that is. And I just say, but it was - they're like, well, yeah, I use Canva.

And it's like, technology now is so amazing and I'm thankful for it. I'm actually really excited because I actually have a confession. I went down the city to pick up a few things and then I actually beelined it to Metrotown because I really wanted to try the new iPad. And I'm sold. I'm gonna go to Park Royal, put in an order.

I have the original iPad Pro and I used that when I did my language. I made a video. I got to see what it was like to make a video, an iMovie, and it was really cool. I had like question one, question two. So my partner - she went to Vegas and I'm like panicking 'cause our assignment's due like three days later or something like that.

After doing my master's going, the language, the deadlines always got to me as a student. I'm sure many of you guys can relate to that. So I was panicking. I asked my teachers, "Hey, wait a sec. I got iMovie, can I just film myself doing this?" So they're like, yeah. So what I did was I filmed a conversation, so I dressed up as two different versions of myself, business self and relaxed holiday Anthony.

And so you could see the energy and just how I said stuff. And it was funny going back and forth. Question one, Q2, all the way up to 10, and then A1, A2, all the way up to A10. And then I combined it all and I made a quick little clip. It wasn't that long. Three, three and a half minutes maybe. But it seemed like it took forever to make, 'cause it was just like splicing it and making sure it was just right.

And I'm sure you guys can all relate is that as an artist you suffer from perfectionism to a fault. Sometimes it's just good just to let that art be. I shared that with my sister. I was like, some of the best mistakes are your best art. So just know.

So also wanted to share that - welcome you guys to the area we know is - really excited that we're having a whole village built. Some of our people will be there too, so I'm really excited to see that. I think that's a reconcili-action piece, so I'm really thankful for that.

The song I wanna share with you guys, it kept coming to me on my way down, is the Sparkle Solum, it comes from Salt Chuck Ball Baker. This song is saying it's held in high regard. 'Cause the eagles are - it said they fly the highest. And so I often ask our guests, singing the song, to think of prayers for your friends or family, anyone that you think could benefit from that.

Those good thoughts, good energy. I think that's such a beautiful thing about us as people is that we have so much we can give in regards to who we are and the energy that could change someone's day, month, week, year. So it's always an honor to share just a bit of who I am and where I come from.

*[Eagle Song performed]*

Thank you guys. For those who know, when we raised our hands, that's how we would say thank you. And then long ago, our people, they didn't travel by car. They traveled by canoe. That was their way. And if you didn't see a walking figure, you just kept going. That was our way of saying it's neutral space here. You can spend the night on the shore.

And that was something I just thought I'd share. 'Cause a lot of people ask me, what is this right? And I'll say, oh, that's the chief.

I just wanted to share that too, is that **humor is what got us through the darkest of times and humor is what will continue to catch us.**

*[Kris attempts to pronounce Isiléyu]*

**[[Kris Krüg]]:** Thank you man. Thank you.

**Anthony Joseph:** Before, we was sending voicemail voice messages back and forth, but for me it's an honor as a language champion to hear the effort. 'Cause that's the only way you get better. So thank you.

**[[Kris Krüg]]:** Yeah. I mean, before he messed up my name tonight and then we all messed his name up over and over again as a group. I've been messing it up all week, back and forth on voice chat, trying to get it right. So thanks brother. Thank you for being here.

For those of you who thought you were coming to a normal technology event, I'm sorry. You're kind of getting a feel for what's going on around here now. You're also getting a feel for why it goes four and a half hours sometimes.

---

## Community Announcements

**[[Kris Krüg]]:** Okay. I talked to a few of you - slapped cookies. Zorro, if you're a community announcements person. Luke, come on up. You know who you are. If there's a Surrey person come. A Loki person come. Do we got a Loki person still here?

### Sesson Ong - UBC AI Club & Government Relations

**Sesson Ong:** My name is Sesson Ong. You can call me SaaS. I'm very new to AI. I only started in August. But I want to be contributing to Vancouver being the most AI forward city in Canada.

I wear two hats. I'm currently an MBA student at UBC, and I quickly identified that the school wasn't teaching us AI. So me and a friend became the co-presidents of the AI club and we're bringing workshops and fluency and all that to the school. So make sure that is in the program.

And the other hat I'm working on is the government relations for the BC AI committee. And so yeah, that's the work I'm doing.

**[[Kris Krüg]]:** We just started a government relations group, about 15 of the BC AI members are a part of it. It turns out **when we all organize and get together and start talking about stuff, people listen** and we need to be strategic about how we approach it. So if you wanna know more about that, talk to Sesson. Thanks buddy.

### [[Loki Jorgenson]] - Victoria AI Summit & MAC

**[[Kris Krüg]]:** Loki, it's been a while, brother. Good to see you, man. A lot has gone on in your world lately.

**[[Loki Jorgenson]]:** There's a lot going on in my world, so I'll keep it brief. Just came back from Victoria, actually. I live there, so I come over here to do these. We had our first AI summit in Victoria in the south island. It went startlingly well, and I got to do the closing keynote.

That was quite the privilege. Kris Krüg was over there, a bunch of us were all over there taking it in. This was part of VIATech's tech week, which happens every year. But the AI Summit - so well run, so diverse, so interesting. They're talking about making it a week long next year. So that's some real ambition.

We collectively offered to be a part of it next year, so I think we will all go over next year as a part of it as well.

**[[Kris Krüg]]:** Yeah. This is gonna be outstanding. So we are really seeing this spreading. We're really seeing a lot of community coming together.

**[[Loki Jorgenson]]:** Those who know me, know them. I'm part of the Mind AI and Consciousness Group. There's about 186 people on that discussion list. You're probably some of you are on there. We meet monthly, 20 people at a time. Our next one is December 11th, and then we're closed for the season. The keynote was in part, based on the work that we've been doing at MAC. And that was extremely well received.

**[[Kris Krüg]]:** They wanted to imagine going to a normal person business conference, for instance, talking about consciousness. That was the closing keynote that Loki gave.

He's doing amazing work. That reading group that he's talking about - if you feel like the conversation about AI is superficial, join Loki's Mind, AI and Consciousness Group. They will fucking kick your ass. And if you want to get into a debate, don't do it on their channels 'cause they're well honed machines. They're going deep.

### Slap Treats - Eliza & Noah

**Eliza:** Hello everyone. My name's Eliza.

**Noah:** I'm Noah.

**Eliza:** And yeah, we're two high school students in grade 12. And we just started a cookie business called Slap Treats.

**Noah:** We named it Slap Treats 'cause you know, cookies so good they slap.

**Eliza:** Yeah, so we cater events. This is our third event so far, which is pretty exciting. And we also do Christmas markets as well as selling in person, just person to person.

**[[Kris Krüg]]:** Let me brag about you. These two, they're both entrepreneurs. This is her second company. She runs a lip gloss and cosmetics company. She's an influencer. She accepts contracts for doing stuff for brands online, all sorts of cool stuff. Now, they started a company together because of this, so that they could cater our events and stuff like that.

And thank you for all your contributions. They come to all the AI and education and meetups and participate so that it's not just adults talking to adults, it's students and teachers talking to one another. I appreciate that you support your bros and the leadership of the Surrey Group. Thank you very much for that.

### Tiny Ghost Studios - Luke & Mayumi

**Luke:** I'm Luke and this is Mayumi and we are running Tiny Ghost Studios, which is an AI animation film studio. And we are after last session, where we had our film showed - The Critical Seduction - I dunno if who saw that? Who was here? Alright, cool, thank you.

So it was so well received and the whole event was such a lovely night that we decided with Kris Krüg and Kevin that we are gonna be putting on an even bigger event next year. So **next October is going to be a huge AI Film Festival.** So keep an eye out for that.

**Mayumi:** And just an addendum to that, my goal in that is to see a lot of first time submitters. So we are going to, for the new year, be putting together some workshops for people who want some help with learning AI tools and animation who wanna figure out where to get started.

And for all the other introverts in the room, I am very, very approachable. Please reach out to me directly if the group chat is intimidating. We can put together some small groups and stuff for you guys. So yeah, love to hear from you.

**[[Kris Krüg]]:** The work you guys have been doing is amazing. So between Kevin laying down the kind of road for the AI film club, me supporting, and you guys standing in doing all the day-to-day stuff and cheerleading. It's really become a sweet group. So many of y'all have made new stuff that was beyond their capabilities even a couple weeks ago. Zara's shit is fucking - we had to cut it from the agenda tonight because it's a little bit tight around here. But I mean, good work and I think the proof is in the pudding.

People are making crazy cool stuff and the overall capabilities both technically and creatively of our whole crew through some of the things that we've all been a part of has gone up. Fuck yeah.

### Matt Lock - Realms Album

**Matt Lock:** How's it going? Um, yeah, just very quickly, the music from earlier this evening before we started, that was my new album that I just actually dropped onto all streaming services today.

A lot of the inspiration and the push to get that done has been through the use of AI tools. Like a lot of the conversations amongst people like Zorro, Luke, and like the larger group - a theme that's kind of starting to emerge, I think is, **AI more for the enhancement of creativity versus the replacement of creativity.**

And I think that album is a really good example. Just again, very quickly, half that album has been recorded as iPhone guitar lines for the last four years. The other half is tracks, electronic tracks that I've made back in 1998 that I was able to bring put into Suno and actually finish something that I'm really happy with. So yeah.

**[[Kris Krüg]]:** It's been fun watching it come together. He's got a bunch of interesting things. You're gonna be seeing his face around here. He is also developed a kind of a design framework and way of approaching projects that he's been developing in public that's really coming some polish on it that I've invited him. Come share another time.

Matt Lock, how you want people to find you, bro?

**Matt Lock:** On our channels. If you wanna search on like Spotify, the group is called Realms. R-three-ALMS. Yeah. So look it up.

**[[Kris Krüg]]:** There's a QR code as well outside. So if you really want to, you can go where the food is, by the monitor, the sound monitor. We put a QR code for his album that just released today, so please do it.

### Zara - SoCo Competition & SimCluster

**[[Kris Krüg]]:** Zara. Right.

**Zara:** Perfect segue from Luke, seeing the AI Film Club going on. I was presented with the opportunity of getting some free credits from one of our members here at SoCo, and it was the first time that I tried to do something like that. So it's funny enough, we entered a few challenges from SoCo together and we came out really well.

**[[Kris Krüg]]:** SoCo is an image and video generation competition, for those of you who don't know.

**Zara:** In the last week's challenge, we got - this is me in the first place somehow. Luke right there in the second. And then we had Michelle - SidBird83.

**[[Kris Krüg]]:** This is Michelle. Global competition with cash money prizes that we're fucking crushing right now. All the way from Japan.

**Zara:** Again, I had just started. I saw, I came to the last meeting and I was like, well, maybe I should try this out. This looks cool. These people are doing some sweet stuff. Asked Luke for some help, and here we go.

So Michelle posted this one. It was about Impossible foods. This was a soup of all soups. And then this one is from Luke - it was a coral cove Boba bowl. And to finalize, I did one. It's the lava cake for a God. So it's a meal of a God. It happens once every eon, and yeah, you have comets and you have our planet as a lava cake. It's simple.

We also participated on the video one. We also got prizes, both Luke and I. So if you haven't tried it yet, come over, talk to us, talk to Mayumi and Luke, and let's participate.

**[[Kris Krüg]]:** Also, don't go nowhere. Zara's playing the stupidest game in the world right now. And did you want us to give us an update on the stupidest game in the world?

**Zara:** Yeah, I can. It's the - it's a stupid game, but it's also genius, right? It's one of those things where you're not like - it's like AI, it's complex. You don't know where you stand on the morals and ethics of stuff. It's a simulated social network where humans cannot post, you can only use AI to make content and you use concepts out of it.

And somehow I, you know, fast paced my way into the first place globally, and I am the weirdest -

**[[Kris Krüg]]:** You want to tell them the prize?

**Zara:** Yeah. Go.

**[[Kris Krüg]]:** This is a skunkworks project like an a16z VC out of San Francisco, like the brightest AI hackers in the world started this weird skunkworks game project called SimCluster.

Zara got wind of it really early and decided he was gonna win it. And he was in 5000th place at the time. **The prize is if you win, your consciousness gets downloaded into a real robot.**

**Zara:** All of the content that you produce while you're trying to get yourself in the first place -

**[[Kris Krüg]]:** Consciousness of your faking.

**Zara:** Exactly. You make a personality and they will download that personality from the game into a real robot and send it to you. So -

**[[Kris Krüg]]:** Told you it was the stupidest game in the world. He's number one on the leaderboard. He is probably gonna get his brain downloaded.

Robot, thank you for all being here. Thanks for coming up and saying hello. And this is how, these are the legs of this community. It's grown way beyond just this event. It's all sorts of stuff now, and this is a lot of who's moving it there.

---

## Lionel Emba - WhatsApp AI Presentation

**[[Kris Krüg]]:** Um, I'm about to invite Lionel Emba back up here. He has exhibited three things over the two years he's been with us.

The first thing was a really cool AI prompting device where instead of prompting it, you put images in front of its eyeballs and then it would blend those things together and generate new things from it. Then he came back and he was like, "Yo, I'm not even sure about the power and impact, the energy." He went for a vacation and he left his computer trained and he's like, "I don't even actually know how much energy it's gonna use."

And so that began a really in depth long-term conversation in this community about the true impact of all this stuff. Not just in terms of power or water or culture as this comes to Anthony, but you know, jobs and all sorts of things. We've been asking the hard questions.

So anyway, without too much further ado, I just wanna draw a straight line. Come on up, Lionel, I wanna draw a line between the conversation you invited us into around power and water and this panel that we're about to have here tonight.

I'm happy these benches are here because you usually like to try to hide in the dark, and I would like to encourage you to stand here in the light.

**Lionel Emba:** Hello everyone. So I'm Leonel. I'm gonna talk tonight a bit of an update from the last time on what is up with AI. So "What" with two Ts, like funny. And I'm gonna talk about open source a little bit also in that discussion and what kind of impact AI has on open source today.

So that was the last time, that was the episode two of WhatsApp with AI where I talked about WhatsApp and project that they developed, which is a GitHub copilot version that actually tells you about and kind of memorizes all the requests you have made and gives you a little bit of estimation of what is the equivalency of this energy use, etc.

Just so you have a bit of an idea. And to give a bit of a summary of what is WhatsApp or the goal of that project is to kind of measure the energy use of AI tools. So you can monitor inside tools that are either in a far distance or on your computer, and also to build a certain language to interpret what does that even mean? How do we make it tangible? And finally, that will be the final goal of WhatsApp or really like the real gold is, is how do we act on this and what do we do about it? Is there anything we can actually do?

So I did present that project at EC this year in Montreal. And that's where I developed a new tool that I will show you tonight.

So this summer Open Router, if you don't know it, Open Router is one of the biggest provider for AI, LLMs, and even Image Generation now. If you want to integrate with a plethora of LLM to directly interact with OpenAI, then Open Router is a great choice because you can easily switch from one model to another.

And one thing they did this summer is that they created a leaderboard where we can see the number of tokens that have been used this week, even shows also for the past months across different providers and different models. And they'll even tell us over time what it looks like.

And so I thought that's a great occasion to kind of, maybe we can add some data on this. And so I built a WhatsApp for Open Router, which basically scrapes their webpage because they don't offer an API. So I did what I could. Sometimes it breaks.

And I used EcoLogits, which is another tool, open source tool that allows you to do estimation based on how many tokens were produced, how long was the request, what is the size of the model.

So here this tool allows you to tell, for example, this month how many gigawatts of energy were used and what is the projected gas emission, CO2 emissions. And soon you will also know about how much water has been potentially used for creating all these workloads. So it's really not about trying to blame or to make or shame or to say this is bad, but to really say here's what it is, and to actually be aware of it, and to continue trying to work towards that.

So we have an idea, is it getting better, is it getting worse?

And in that tool also built in some equivalences, so we can have an idea. What does that even mean? There are other screens on it where you can see, for example, how many kilometers in a car it is, or things that are a bit more relatable.

And through this I started working a little bit on the second step of that project, which is to be interpreting this data. Some other projects already did some work. For example, the AI Impact Tracker here that you can install in Chrome that tells you information about your ChatGPT usage.

This is very specific to ChatGPT and it continuously monitors your usage in Chrome, is local for you. And so from there they develop some kind of language of environmental equivalence. So we have an idea of what does that even mean? And so in WhatsApp for GitHub Copilot, I kind of started reusing that with, also like the famous, "how many hours of running a microwave."

And here I'm gonna talk about EcoLogits, which is the tool that I use in both of those tools. EcoLogits is a project developed open source, and they have made a big improvement in their methodology, which also integrates water consumption. And also they have really improved the accuracy of the model estimation of how many parameters in a model and also for open source models, what is the actual energy use of these models.

Also, including things such as the water usage of certain data centers. So you have an idea also, for example, the power efficiency, if it comes from Google, if it comes from AWS, you can have different efficiencies.

And a bit of the good news, Google published an energy report recently as a paper, which is measuring the environmental impact of delivering AI at Google at scale, at Google scale. Finally. Yeah. That's great. It's a good move. It's actually a positive thing to see, and hopefully we will see more and more companies doing that.

So it's the first, the first methodology is very holistic. It shows on the right side as part of the paper, a screenshot that it takes into account really a lot of the lifecycle of a server that's running AI, not just like the chip utilization, but also all the way to machine when machines are able, or like the overhead of running a data center.

And this methodology can be used by other companies and other data centers to do the same and do a more precise measurement that is actually really taking the entire data center. It's not just about estimating almost the GPU use, but how much does it cost to run that whole thing.

And there is some interesting part. They determine that it takes **0.24 watt hour per prompt and five drops of water per prompt**, which is interesting, but it's kind of problematic in some way because those measurements that they define the standard are not comparable because it's per prompt means it's very hard for you to compare to another company if they were doing it because a prompt is not the really unit of measurement of AI. When it produces the token is the real measurement.

So hopefully we'll see new paper coming up with measurable and comparable values and hopefully companies don't continue using that value because that's not very useful to actually know if we're doing better.

And another thing - it's great that they did this, but while they're doing this, they have Google Gemini is a really big model and this is one area where we really don't know.

**Open source is really the reason why we know all this.** There would be no data on this matter and Google probably wouldn't step forward to do this otherwise. And right now, all the larger flagship models don't tell us anything about their use. And they are the big ones, the ones that's really interesting and juicy.

And there is almost no data on video models today. And that's very important because those, we have a quite good intuition I think that they would be using a lot more than text models. And absolutely nothing on world models. And those are very cool models. But also the energy use, we have no idea. And there's no open source world model as far as I know.

So we can't really tell. And user privacy is kind of crumbling because it uses more and more of that closed AI because think about what you - the questions that you were asking when you use the search and what kind of things you tell to ChatGPT because it's a chat, it's very different.

And so I'm gonna talk a bit of a project, open source project. For example, the curl project. It's a very important project that runs the internet in so many ways, is basically how a lot of software make requests to servers. And recently the maintainer has wrote this article, where they started receiving on HackerOne. HackerOne is a platform where you can post vulnerabilities that you find about software and they can give you money back for finding actual problems.

But recently in July, they spent eight times more time on vulnerability reports, but actually **only 5% of those reports are legitimate.** So they're basically spending time on reports that are absolutely not reproducible. They're completely hallucinated. So that's a bit of a problem. And that's kind of like really overloading open source that is already running on low funds usually.

**[[Kris Krüg]]:** So you're talking about hackers seeking bounties are using Claude Code and shit like this to try to find vulnerabilities in curl, but they're not there. They're hallucinating them. They're submitting them anyway and they're wasting all the people's resources of the open source project.

**Lionel Emba:** Exactly. And the blog is very interesting. Please read it because it gives details about it.

And that's another project, FFMPEG. It's a different problem. It's also an open source project. Very important project because it runs all the streaming online - YouTube, Netflix, think about any streaming platform uses FFMPEG in some way.

And Google Big Sleep, which comes from Google DeepMind, is a very big system that is very good at finding vulnerabilities and actually making real vulnerabilities, true vulnerabilities actually, and publishing them.

But their policy is that if within 90 days you haven't fixed it, we will reveal it. So now there are tons of projects that are open source that have this ticking bomb from Google, a trillion dollar company, where there's open source projects that don't have much funds and certainly no time to execute so fast on vulnerabilities.

And all of a sudden they get 20 vulnerabilities. Some of them are actually naturally exploitable and what do they do? Because in 90 days they will have actual vulnerabilities revealed in products that we all use and they don't have the time to fix it. See how this could be very discouraging for open source maintainers to continue maintaining this project.

**[[Kris Krüg]]:** You've exceeded your time, so I'd like to give you 30 seconds more to wrap it up and then we'll talk about the award.

**Lionel Emba:** So recently OpenAI had this token consuming award, which is very interesting because they're actually rewarding people for consuming a trillion tokens. Is that the right incentive? What are we gamifying here? What is this gamification?

So I did an estimation. What does 1 trillion tokens actually mean? And here are the numbers. It's the **energy use of 52,000 households daily energy use.** That's 1 trillion token or **3.5 million kilometers driven in a car.**

Not saying it is good, it's bad, but here what is - probably some of you have received that award, but that's okay. I'm not blaming you. I understand. But it's like what are they trying to reward? It is kind of interesting.

**[[Kris Krüg]]:** It's actually - I want to both be conscientious of time but also expansive. They're rewarding with that award - they're saying that there is work that is being done, valuable work of some sort that's being done. And they're trying to optimize. They're not just like, who can blow a million tokens down the toilet. Most people are trying to do useful things such as science, research, healthcare, video games, and entertainment.

**Lionel Emba:** I agree with you. I'm not saying the award is completely bad, that people using tokens is bad. What I'm saying is what is it rewarding? Because they clearly took this from YouTube, which is a democratic system where people actually subscribe to community, like videos that they actually enjoy, versus something that is actually paid, literally paid for, and now the number of tokens consumed does not bind to value delivered like a revenue of a company does not mean it's actually delivering value.

That is the thing. But definitely meaning that using tokens to do something useful is true. But is that the measurement of value? Probably not. I don't know. What is the measurement of that value? Community can say it with different - whether it's not revenue or tokens used.

**[[Kris Krüg]]:** And as our conversations go deep on - it's like until you can even see what you're using those million tokens for in terms of impact, how do you ever make a choice between a better performing system in terms of impact or a worse performing system? You have no choice. You have no ability to even see those things. So monitoring your usage is the first step I think. Hitting targets and reduction all.

**Lionel Emba:** Exactly. And that goes right into the award. So I was thinking about this thing. **What if we turn this onto its head and actually created an award for saving tokens?**

So maybe we can do something with BC AI actually, and make an award a part of this. But the idea is like, what if you here have found a way to save 1 million, 10 million, a hundred million tokens? It doesn't really matter what the tier is, but let's say you saved 1 million tokens this month by doing something.

Please let us know about it. Let's write about it, let's talk about it and let's share it back to the community so we can actually make progress toward - not using less of AI, but make a more sober use of it. And not just wasting tokens, but actually have an award that is gonna actually really contribute back to the community in a positive way.

**[[Kris Krüg]]:** Yeah. Business talk. They say if you want to change the outcomes, you change the incentives. Well, how about we give out awards for how many tokens you can save instead of how many tokens you can use.

**Lionel Emba:** And there are some flyers on the outside if you want to subscribe to the newsletter of WhatsApp or see the website, see how you can contribute or contact me. Please pick up a flyer on your way out.

### Q&A with Lionel

**Raghava:** Hi. Thanks for the presentation. I'm Raghava, I own an AI firm I founded in March of this year. So I was kind of intrigued by one of the comments that you had in the slide. That user information is crumbling with closed AI. How do you define closed AI first and then, because your premise for the presentation was open source, how do you interpret open source to actually not do the same?

**Lionel Emba:** So I guess there are many interpretations of open source, that is true. And when I talk about closed AI and privacy, I talk about AI that you cannot run on your computer, for example, that you wouldn't be able to run on your own hardware. That you have to actually send your data to a company for it to process it for you and give you an answer as opposed to something you can ask locally and you can be sure that your privacy is preserved.

Usually those models are open source. I don't know of any private source model that ships on your computer so far, even though it's probably on your iPhone, but these are the different type of AI.

**[[Kris Krüg]]:** Clearly, open source software, we can all write tools and monitoring stuff on top of it. Closed proprietary systems, you never know what's going on under the hood. Traditional definition.

**Audience Question:** First question, when you did the CO2 emissions calculation, I'm just curious, like, was there a way to figure out if the energy was actually coming from renewable source, or did you just assume it was like a hundred percent like fossil fuel based? And is there a way to kind of like change that depending on where it's actually coming from? The data processing.

And then I like the comment on incentivizing like saving tokens. But I think right now a lot of these companies that are selling this computational time and capacity are making money from that. So they're incentivizing usage 'cause they make more money from that. But I think if we're gonna incentivize saving, then I guess it would be cool to find a way to actually make, monetize that saving as well. So there's a financial backing for it too.

**Lionel Emba:** How is it calculated? So in this case, I use the world electricity mix. The tool Open Router, WhatsApp for Open Router, you actually have a setting somewhere where you can choose that energy mix. I'm planning to improve it so that based on the different provider you have, you know which energy mix is tapping into.

So you can say it's gonna be maybe like this region is gonna be USA and if different places you'll have different energy mix. But there's a tool, there's a way you can change that in the UI as a setting that you can try and simulate like in WhatsApp for Open Router. I don't know each model's parameters. So I just defined it as 20 billion parameters in average for everything.

So if you crank this to 40 will be a lot more. So that's how it's kind of evaluated. There are some assumptions of what energy mix or billion of parameters at the moment, but we can improve this over time.

And about the monetization - I agree with you. Everybody's running right now, it's an actual global stampede of AI. Like Google didn't wanna run at first, but OpenAI did it. So Google started running. Everybody's running and we are all trying to - let's go as fast as we can.

And I hear a lot that this is inevitable, but I disagree with it. I think it's inevitable - we just don't have to contribute to it. We can slow down. We are not gonna miss anything. There's nothing to be missed on. Of course, if we think about money, we're gonna miss on some money, that's for sure.

But as humanity, I don't know if by going faster we're gonna earn something more. So I don't have like a way to - I'm just thinking about like, this award, how can we make this award more interesting? But to me, the reward is that we get to contribute to the larger community by sharing our findings. You know, really trying to know what we're doing with this.

**[[Kris Krüg]]:** Thank you. You've been challenging us since the very beginning. Lionel is a first order programmer. He's a first order artist. He's a first order thinker. If you're interested in this stuff, connect with Lionel. Good job, man. Thank you, sir.

Have you ever been the warmup band for somebody else? Lionel. Have you ever been the warmup band?

**Lionel Emba:** What is a warmup band?

**[[Kris Krüg]]:** The band that goes on before the main band to get the crowd in the right spirit.

**Lionel Emba:** No, but I guess that's it. Congratulations.

---

## Amanda Silvera - Voice Theft & SOBIR

**[[Kris Krüg]]:** Okay, up next - but before we get there, I wanted to invite up a new colleague of mine, Amanda, who is here to talk to us a little bit about an experience that she went through that is kind of related to all of this stuff and helps to kind of give us another perspective on it.

So a lot of us are doing AI stuff for a long time, and we hear about stories of people whose likeness or artworks or voice or video likeness has been taken from them without their consent and used for things. Who knows, money making, nefarious things, all sorts of different things. But I think that it's difficult to connect with some of those stories unless we know somebody that it's happened to.

And so, Kay introduced me to someone recently who it's happened to, and Kay's a panelist here who's gonna be coming up for the next panel. So thanks for being here, Amanda. And Kay, I just wanted you to come up and introduce Amanda and tell us why you invited her to be a part of all this, please.

**Kay Tigo:** Hi. How's it going? My name is Kay. You'll learn about me a little bit more later, but for now, I would like to put the spotlight on my friend Amanda.

Amanda Silvera is the author of Chapter 11.3 in the State of AI Ethics report, which we published at the Montreal AI Ethics Institute.

Amanda is a Canadian voice actor and entrepreneur committed to fighting for AI ethics, creative rights, and biometric identity protection through her organizations - Society for Original Biometric Identity Rights, and Society for Original Biometric Identity Rights Technologies. She advocates for responsible AI governance and human authenticity.

She's the voice behind Psych to Go, which has 12.5 million followers on YouTube - 12.9 now, almost 13 million. And her voice and likeness were scraped and is now being used without her consent. So here is her story.

**Amanda Silvera:** Thank you, Kay. Thank you so much for having me. It is an honor. I'm gonna get comfy and sit down.

I've got a little bit written here, but I'll start by just telling you a bit about the story. So I'm a voice actor. From 2017 until now, through Psych to Go, we have posted thousands and thousands of videos, which have been reposted all over the place - Snapchat, any platform it's being reposted legally or illegally, which offers up a whole bunch of data that can be used for different types of cloning and voice tech.

So it was brought to my awareness that there were two platforms on YouTube that were using my voice, and it wasn't just text to speech, it was literally they speak into the microphone and my voice comes out.

It was really crazy because it was so good that I'm sitting there and I'm like, did I say that? I absolutely did not.

The first instance was the most disturbing so far. It was a gentleman who was using my voice **to pose as a young girl and lure older men in**, posing as this young girl. And it was all, you know, live videos of these men. And my voice was being used to seduce them.

It was very, very disturbing. And it's still happening now.

The frustrating thing was as I came to find these different platforms and different people using my voice, **I was hitting a wall when it came to my rights. I was hitting a wall when it came to how much of my voice is even mine.**

And even when speaking to people in law, we were all frustrated with the sense that there is a very gray, murky area when it comes to almost every part of our identity and our creations and everything that comes from us as humans. Our art, our thoughts, our poetry, our homework at this point, everything is kind of just being regurgitated.

And the gray area is kind of what I'm working on now. As I was sending DMCA requests and once one was down, I was being uploaded somewhere else. There's Reddit threads looking for this user who had this great clone and "oh, I believe it's the Amanda Silvera voice model. It's the Amanda Silvera voice model. You can find it here. I have it here."

It doesn't matter. I could spend hours every day fighting to get one clone down and another five are popping up. And the more popular the clone is, the more it's gonna continue to be re-uploaded in private places that I can't find behind paywalls.

So that's why I decided to kind of move over to fighting for not just me, but for everyone who has a voice. So all of you. We should have rights to our voices.

I use my voice to gain access to my bank account. I don't know if those biometric identifiers could tell the difference between me or the clones that I was listening to online. I really don't know.

So I founded the Society for Original Biometric Identity Rights and we're pushing for policy changes and legislature that will protect us slowly but surely. This happened in like March. So it's been a whole lot happening at once.

But the missing piece is that we have Denmark who has made amazing strides towards protecting and copyrighting our likeness. I think in the EU and in America, there's the Elvis Act and a few different things happening. It's great. The idea that we could copyright our voices or our likeness, or our biometric identities, our gait, our likeness, our eye, our corneas, retinas.

That's great, but we can't protect what we don't know about. There are versions of these things all over the place. I can't keep track of them. And if I don't know about them, I can't fight for them. I can't protect myself.

But I don't think that that's a problem that we can't fix at this point. We have a problem and it has come because of AI. But I think that the solution in this case, the antidote may actually also come from AI.

The missing piece is just how do we keep track of where everything is and how do we also verify with confidence - kind of like how do we get a confidence score to say that this is close enough to your voice that we can confirm that that's where it came from.

These are things that we're gonna have to figure out when it comes to legislature and protecting ourselves.

It's an exciting time. **I also wanna make a point that it's not AI that's doing this. It's people. It's people abusing something.** So I think that's an important point. All of the issues that we're facing, it's not AI's fault, it's how we're using it.

We need to be a little bit more responsible and we need to be filling in these gaps, especially in legal. We're racing to catch up with something that is continuing to evolve and improve and grow exponentially. And every time it grows exponentially, it's growing that much more. We can't keep up, but we have to try.

So that's my story. I have a petition on change.org - it's going to Minister Evan Solomon. There's already 5,300 signatures. We want all of the signatures. We want infinite signatures.

**Sesson Ong:** I work in government relations. I changed how to work. Like there's a platform called Lead Petition. It'd be great to get these people to pay attention of like, what's the kind of damage that the average person's going through, that their identity and their self can be taken away.

**Amanda Silvera:** It can happen to anyone. If you posted anything on Instagram or, you know, it can happen to anyone. It's not just me.

**Audience Question:** Does this extend past voice to physical identity? Particularly around the use of like, AI pornography?

**Amanda Silvera:** Yeah. There's actually something out there that I haven't been able to see behind a paywall where they're saying it's my voice and I don't know what else.

It needs to extend to physical identity. Absolutely, absolutely everything that makes us human, for sure.

If anyone in BC government's in the room, BC government's doing a little bit of work around this identity. It can affect us all. And be life changing if it happens. It has not come out yet. And because there hasn't been enough people who've experienced what AI can do for the negative.

We all want this protection, man, woman, and child. It may be rare right now, but it won't be rare for long.

My final note - I did mention the tech that I'm working on conceptualizing. I've run it by a few people. And I'm really hopeful for it because I've experienced this. I know what we need. I know what we need to fill in the blanks.

So right now I'm looking for:
- Senior machine learning engineers specializing in voice and audio
- Generative AI safety detection engineers, focused on deepfake detection, synthetic media identification, and watermarking
- Cloud architects with data sovereignty experience
- DevOps engineers to build scalable, secure systems
- Biometric focused cybersecurity engineers
- Data privacy engineers
- Policy and compliance technologists
- Product map developers

That's it for now, but it's gonna be a lot. But if you or know anyone who are those and wanna chat, let's chat.

I love us, I love humanity. I love our voices, but I also love our planet and I love the conversations that are coming next. They're very, very important. And I'm gonna stay close because I also have quite a few things to say on the matter. So thank you guys. Thank you so much.

---

## Ethics Panel: "Portals Not Panels"

**[[Kris Krüg]]:** Catherine Warren has been a member of this community for the last year. It's so cool to reconnect with you Catherine. We knew each other during the web 2.0 days. She's a powerhouse, and has been a big part of the economic development technology communities here in British Columbia for a good long time.

Also, our graphics have always been fucking awesome, but they just got another major up level. This guy right over here, [[David Weng]], has taken over as our art director and has completely expanded our capabilities. So David, thanks so much, bro. It's been great having you helping out, man.

Catherine Warren, who knows Catherine. A couple friends out here. Thank you so much for pulling this together. I fucking hate panels. And I went there to support you. Kay and Kevin we're all in the same thing. And you introduced me to Liz, whose work is amazing and made me realize you shouldn't judge shit. You should definitely approach every single thing with an open mind. 'Cause this is some good shit. So thank you for coming here. It's not easy to pull four or five people together in the same room at the same time.

### Catherine Warren - Opening

**Catherine Warren:** Welcome everyone, and especially welcome to our newbies here. It's really great to see so many new people in the room and I appreciate very much being together in one of the world's greenest cities. And AI powerhouse also, talking about something that is very much - and I really appreciate the fact that we're here in a creative economic sector as well.

So by way of background. **Vancouver is a global powerhouse when it comes to media and entertainment. We're also the home of Adbusters, Greenpeace, and many other action oriented media and activist organizations.**

So we are very much right place, right time to be having a conversation at the intersection of artificial intelligence, sustainability and the creative economy. And I'm very happy to be here with three entertainment thought leaders.

And I also wanna thank Anthony for convening us on the unceded territories of Squamish Nation. I am so grateful to be here and magic happens when you convene with purpose. So thank you so much, Anthony.

As Kris Krüg mentioned, I'm your moderator, Catherine Warren. I'm the founder and president of FanTrust and we are celebrating our 25th anniversary this fall at the intersection of innovation, entertainment, and economic development.

And you know, thinking back, since about 2016, innovation in these areas has tended to mean artificial intelligence, sustainability and inclusion. So we'll be talking a bit about those as innovations.

And my own background in climate physics actually launched me on this trajectory many years ago, and a commitment to climate leadership.

And much later in my career as CEO of Vancouver Economic Commission, I had the privilege to oversee our film commission and also do a lot of work in the circular and green economy. And what I learned from that is that you can do well by doing good and that these things aren't mutually exclusive.

So to work in sustainability does not take away from the bottom line. And in fact, it can contribute to new revenues, relationships, and reach.

Somewhat later, I was recruited by the mayor of the City of Edmonton to come out to Alberta's Capital. And there I launched an **ethical artificial intelligence accelerator fund**, and we focused on AI for social good.

So we're gonna be talking a bit about that and where sustainability and the green economy fits into things like the sustainable development goals. So let's get into our topic at a high level, and then I will introduce our panelists.

I really see AI as a double-edged sword, or maybe even an AK-47. It is ubiquitous, it is powerful, and it is very dangerous in the wrong hands.

And when it comes to the climate emergency, we are faced with a paradox. On the one hand, AI of course, promises to help us solve a climate crisis, a climate crisis of our own making. But on the other hand, AI's insatiable energy consumption could just as easily push us past the brink. So it's sort of a battle that's going on there.

But the truth is **we don't need intelligence, human or artificial to address the climate emergency**, right? Any dumb dumb can do it. We know exactly what to do. We get off carbon full stop. We've known this since the eighties, and that was a gentler time. It was a time when we actually had a lot more time to do something about it. And it was a time when all the facts already known to women were out there for the taking. The research was in in the eighties.

So this is not in fact an intelligence problem at all. **It's a problem of political will.**

And so, put simply, can artificial intelligence fix human idiocy? Or have we, with all of our intelligence just created a smart machine in our own image, essentially another energy monster. Machines, they are just like us.

At COP 30 this month, AI moved for the first time from the sidelines to the front lines. And the conference highlighted the potential to do things like cut emissions, harness energy and water sustainably, and warn communities about the impact of climate threats - as if we needed any more warnings.

But real concerns still remain. There are no global standards to measure or control AI's carbon footprint or water or energy, and AI driven climate misinformation is exploding.

So we're gonna talk a bit about that. And my question for all of you as you listen to our panelists is: **Will AI help us tackle ourselves and be the better person? What role can AI and the media industry play in saving the planet?**

And we are about to find out from our expert panelists:
- **Kay Tigo** - Director of Marketing Communications at the Montreal AI Ethics Institute
- **[[Kevin Friel]]** - AI filmmaker and video producer
- **Liz Marshall** - filmmaker of Liz Mars Productions

### Kay Tigo - State of AI Ethics Report

**Catherine Warren:** I'd like to start with Kay. You mentioned moments ago, when you introduced Amanda, that your organization just released a new report. Tell us about your work at the institute and your research findings as they relate to both entertainment and sustainability.

**Kay Tigo:** Thank you so much, Catherine. So I am the global marketing Director for the Montreal AI Ethics Institute. Earlier this month, we published the State of AI Ethics Report. It basically covers various sectoral applications of AI, from sustainability to healthcare, military, and entertainment, and everything in between.

So please read it, download it, it's free. If you go to **montreal.ethics.ai**, you can find the report.

But I wanna tie back to a point that you made, Catherine, before I dive in a little bit further. When we were prepping for this particular panel, I was reminded by a biologist, Edward Wilson, who argues that **the problem with humanity is that we have paleolithic emotions with medieval institutions and godlike technology.**

And when we examine the intersection of AI and climate change, the problem is not theoretical. As Catherine mentioned, it's very political. It's about political will, but moreover, it's also existential.

So going back to the report. It was quite a feat to put together. We had **58 contributors, including Amanda, 48 essays across 17 chapters**. It was an enormous effort.

But overall what we found is a growing power gap between the people creating AI technologies and the policies around AI. And on the other side of it, are the people using it on the ground, particularly the people feeling its adverse consequences.

And public policy should really protect the most vulnerable members of the population. Policy fails when people who are most affected, again, who have to live with the consequences, are not included in conversations that will affect their lives, particularly public policy conversations and especially so when public policy consultations are mostly theater.

So I think - and I'll echo my colleague Abhishek Gupta, who's a co-founder of the institute - **we failed to implement thoughtfully if we rush to deploy new technologies.**

And for example, just to ground this conversation, according to the MIT Technology Review, **five second videos produced by new gen AI models used 3.4 million joules.** That's more than 700 times the energy required to generate a high quality image.

**This is equivalent to riding 61 kilometers on an e-bike or running a microwave for over an hour.** And that's just for a five second video.

Of course these numbers are estimates because it's a black box, we don't really know what the real numbers are, because AI companies are not transparent and forthcoming with their energy usage.

So these estimates don't capture how we'll use AI in the near future. So really in many ways when we think about it, right now is probably the smallest footprint we'll ever have when it comes to AI use of energy and water consumption. So we are not even looking at how burdensome AI can really be on local power grids or local wastewater facilities.

**By 2028, researchers estimate the power going to AI specific purposes can increase to 326 terawatt hours per year, which is comparable to the annual power usage of certain countries.**

To put in perspective, 326 terawatt hours generates the same emissions as **driving over 300 billion miles. That's over 1,600 round trips from earth to the sun.**

In the recent COP 30, which just wrapped up earlier this month, what we've seen is a slew of broken promises. Nations around the world have failed miserably in stabilizing the amount of greenhouse gases in the atmosphere. So now climate experts are saying it's inevitable that global temperatures will exceed 1.5 degrees Celsius, which is the limit that we had set for ourselves several years ago.

But what is the significance of exceeding 1.5 degrees Celsius? According to the Environmental and Energy Study Institute, this means:
- More frequent and intense heat waves, wildfires, storms, and floods
- Nearly 1 billion people will be exposed to water stress and desertification
- $63 billion in adaptation and residual damages to major crops
- 14% of the world's species at risk of extinction
- 24% more people would face flooding compared to historical levels
- Coral reefs would decline by 70 to 90%

**Building data centers on mass will only accelerate global warming.**

What we're seeing in governance is the infrastructure isn't ready, the literacy isn't there, and the participation mechanisms are broken. We're moving too fast to ask the right questions about deployment, consequences and accountability.

Each new investment cements the current trajectory unless equity and justice are built in by design. And we truly believe that we can do that if we have the will to do so.

**Humanity is at a crossroads and how we proceed will determine whether we're doomed or redeemed.**

### [[Kevin Friel]] - Compute & GPU Monopoly

**Catherine Warren:** Very, very sobering and well said. And you know, everyone in the room here is here because you care about this topic. We're early enough in AI, still a relatively new technology, that if we put it under this kind of scrutiny and apply policy to it, we can turn this around.

The other thing that you made me realize is that even without AI, we've been creating a lot of garbage videos using our own digital footprint as humans. And we never put that under the kind of spotlight that I think AI is going under. So maybe it's time to also look at the stuff that we are creating ourselves.

And the other thing of course, is AI is now embedded. It's stealth, it's in almost every tool we use.

So with that, I would like to turn over to you, Kevin, and ask you as an AI filmmaker who's using these new tools every day, how are you keeping it green? How much of what you're using has what I would think of as like stealth or embedded AI versus intentional AI?

**[[Kevin Friel]]:** First of all, I want to welcome you all to my living room here. Would you like some snacks? There's some nice drinks at the back.

When this whole sort of redux of our conversation that we had at the sustainable production forum a few weeks ago - I was blown away by the diversity of information and experiences and the conclusion that really hit a focal point in the middle. And I'm really excited to find new information, new fulcrums in that, and of course with all of you as well.

In terms of the compute problem in production, **compute in creating content is not a new problem. What we're facing right now is an exponential scale of compute that we have never seen in an exponential scale of creating content**, not only by established firms such as visual effects companies or large movie studios, or perhaps even indie producers.

But the everyday person, by virtue of the speed of our internet now, allows one-for-one access to incredible amounts of compute that we have never had access to before.

And that creates an interesting paradigm in that those of us that have been living and breathing GPU compute for 15 to 20 years if you were an early adopter for it, we saw this coming in a lot of ways.

We've had to deal with power management. We've had to deal with cooling all along, before water cooling was really affordable and attainable on the scale of render farms that we would have. We were maxing out GPUs in the late 2000s in this sense. So this is something that has arrived at such a scale that nobody was really prepared for except for a few of us that were lucky to see it early in the front lines.

So all of that to say, there's a two-pronged approach and problem and quandary that we have in terms of production's relationship to compute.

First, the compute that we can control and that's local. We can use efficient code, we can use efficient compute.

One of the parts that I really wanted to introduce into this conversation tonight is efficiency of compute itself. **The design of the efficiency of compute is deeply problematic in GPUs.**

**We have one major player who is providing compute on the GPU scale to everyone - the $5 trillion elephant in the room, Nvidia.**

And the reason that they have such clout is it's not just hardware design, but they have embedded their software so well and so deeply into being the only compute platform that is accessible and reasonable at scale and local compute processes. They're the only game in town.

There are other hardware vendors, but no one wants to touch their software 'cause it just can't - **Nvidia has a 20 year lead on hardware and software interface** to make all of these things happen.

So when we look at that approach, we look at alternative ways of computing, and we've done that already on the CPU side. For instance, when Intel was ruling everything and AMD came up and beat them by creating better compute for cheaper, for less power and for less heat output.

And then ARM came along and with partnerships with Snapdragon and with Apple have revolutionized CPU compute and now systems on a chip where you can do equivalent to Nvidia 4090 compute at 40 watts, whereas an Nvidia 4090 hits 500 watts at times.

**We need that exact same paradigm to happen on the GPU side.**

And you know, we really have an amazing opportunity as Canadians to actually lead that. We have so much history in companies like Nortel and TeleSat and Blackberry, where we have introduced real paradigm changes in technology in the world.

And there's companies that I'm aware of in my hometown in Ottawa that made all of the car OSes for Ford for years and years and years. This is not a - it is a big thing to ask, but we have history in doing it before and the people are here.

So that's the big lofty thing that we need to start working towards. And I'm planting that early 'cause I want that to happen not only for the environment, but for us as a nation building initiative, and all the partnerships for that to come on board with.

And what that would allow is much more control of local compute, therefore less heat, less power, less dependency on a single provider, to empower all of these things and actually have some healthy competition start to happen.

'Cause right now we can control local compute by having a set amount of servers, a set amount of GPUs, and a set amount of cooling at any moment. But we're always gonna have an overrun and we have to go scurrying to Microsoft Azure, Google Cloud or AWS really.

And we have no idea which AWS cluster we're actually pulling from. They say that they have more environmental clusters, but are they actually really provisioning us that 100% of the time? So that sense of compute helplessness and the fundamental design of compute itself is the single biggest paradigm that I think that we as a species need to take a look at.

'Cause compute is starting to be just as important as hydro and electricity and food and all the things that we hold as a society. It runs everything. So that is my fundamental argument. **It's compute. We need to solve compute design in a major and incredible way if we're going to make anything good out of this.**

### Liz Marshall - Water on the Table & AI/Water Documentary

**Catherine Warren:** Alright, so Liz. You are a career documentary filmmaker and you are revisiting a topic that was very powerful to you sometime ago, and you're giving it a whole new lens. So I would like you to tell our audience about your first documentary on this topic and now what you're doing in 2025-6 plus.

**Liz Marshall:** Hi everyone. Hey Kris Krüg. Thanks for initiating. Kris Krüg was a fan of this panel a few weeks ago. We were in a room speaking to film and television industry specialists.

Everyone cares about the environment. Can I get a raise of hands? Who's an environmentalist here? Who cares about the climate? Who cares about water, earth, air, trees? Yay. That's most of us.

So yes, I am embarking on a new epic feature documentary currently. I'm at the - I would call it phase one development stage, and it is a revisiting of a very big subject matter.

15 years ago, my very first feature length documentary is called **Water on the Table**. And I was so privileged to be able to shadow and witness and follow the tremendous work of Canadian Maude Barlow, when she was in her appointment at the United Nations as the water advisor to the president of the General Assembly.

And her mission was really about enshrining water justice, so the protection of water from the greed and exploitation of the so-called free market of the private sector, which is for profit.

And water justice. The ethos of water justice is essentially that **water belongs to the public commons. It belongs to the earth, it belongs to future generations. It belongs to all species, it belongs to nature, and it belongs exactly where nature put the water.**

It should not be diverted, drained, moved, exported, because we know there's evidence to back it up that it creates drought and desertification.

So water justice is something that I became extremely passionate about when I made Water on the Table 15 years ago.

So fast forward to now I'm asking the question, **"Is AI draining this world for another?"**

Now, that's a big meta question that I really look forward to going really deep because the intersection of AI, data center expansion and water use is really an intersection. It's like an epicenter, containing many ethical questions. Many unfolding big questions that we don't know the answers to yet either. But there's a lot of data coming in.

We know that it's estimated that **by 2027 data centers will guzzle up 1.7 trillion gallons of water per year.**

When we look at this magnificent country, Canada, Turtle Island - we know that we are blessed. **We have 20% of the world's fresh water, yet only 7% of that is renewable.**

So we're living in a climate emergency. There's no argument, no debate. And we have raging forest fires in this country. We have drought. **There are 36 indigenous nations that are still living without drinkable, potable clean water.**

That's a reality. That is a human rights, horrible, shameful issue that we have not solved yet.

And so I guess really, I'm here kind of repping water. I'm repping the air. I'm repping trees and earth and power to the people.

I'm also a nerd. I made a documentary - it was released in 2020 - it's called **Meat the Future**. That's MEAT. Meet the Future. It's all about human ingenuity. It's about cultivated meat. It's about a solution. It's using technology, in this case, food technology, to solve one of the biggest climate issues of this planet, which is animal agriculture.

So I am not in any way, shape or form, like a full on tech resistor or definitely not a Luddite.

But I've kind of thought about, you know, who am I right now in the world. What are my values? What the fuck is going on? Everything's happening so quickly. There's the rise of fascism happening at a crazy pace, and it's been very discombobulating and we're all kind of trying to get our balance, find our voice within that and find meaning and purpose around ways to move forward.

The four pillars that I have kind of come up with - **CASK: Curiosity, Awareness, Skepticism and Caution.** That's specifically about AI.

So the wonder, the romance stage - leaning into this sort of like, oh wow, this is mind bending fascination, that whole thing. That will continue, but I think we're now in a more pragmatic stage where we can talk statistics, we can talk pragmatically about the value systems that are embodied here.

So when I focus this new documentary on the intersection of AI data center expansion or sprawl, or growth or whatever you want to call it, and water use - for example, the Great Lake Basin is an epicenter of growth, growth, progress, so-called progress. That is scary.

And of course, indigenous ways of understanding the earth, indigenous ways of knowing - indigenous nations do not recognize colonial boundaries. And they certainly do not say, you know, that's our water or your water or our land or your land. No, it belongs to all of us.

And if we are truly environmentally conscious, if we care about this planet, then water needs to be the sacred life blood of this earth. Then we really need to look very critically at this issue and figure out a way forward.

I have a lot more to say. I'll end just by saying that **the resistance has arrived.** We can look to models right now in Georgia, Indianapolis, and Virginia - there's a tremendous community resistance and it's been very effective. In fact, there are now **moratoriums on new data centers.**

So people have power. We have to remember that. And it's coming here, and I am going to be on the ground witnessing the unfolding of the resistance.

### Panel Discussion

**Catherine Warren:** Thank goodness for storytelling, activism, and your work. Liz, thank you so much.

You're making a difference in the moment when people can do something about the problem. And what we've just learned from Liz is that these machines are very thirsty. They are thirsty, thirsty machines, at a time when many people in the world are very parched.

And so we're not only working hand in glove with artificial intelligence to solve problems like the climate crisis, but AI is in a sense, a rival for the very human resources that we need for our survival.

So quick show of hands in our audience. How many of you think about the carbon cost when you query ChatGPT? Okay. A few of you do. And that's pretty good because Vancouver.

So I believe it's something like 0.1 gram per prompt. And now there are a lot of us with a conscience in this room. But the question for me is, and I'm gonna turn this over to our panelists, where is the corporate responsibility around that?

We're taking individual responsibility. Where is the corporate responsibility, the AI carbon costs of training these models and the role that corporations can and must play in greening what I'll call the AI grid.

So, Kay, I wanted to get the audience to hear from you, what your report has to say about corporate responsibility.

**Kay Tigo:** So I think when we talk about corporate responsibility, it's a little bit ironic for me because when you think about the history of capitalism, one, have corporations ever been intrinsically motivated to uphold human rights? This is a very important question to ask because truly, when you think about it, **policy is one of the biggest ways to get corporations to actually do the right thing.**

Corporations are very singular in their purpose. They are there to make money. It's about profit.

So when we're talking about corporate responsibility, to me, what comes to mind is actually the immense work, the groundwork that has been laid by the labor movement and in terms of motivating public policy that supports human rights in general, but also protection for the environment.

And I think in this age of AI, we need to be asking ourselves, okay, well if corporations were, let's say, hypothetically speaking, interested in actually upholding corporate responsibility, then why is AI a technology that is essentially built on theft?

So that's a good question. Like ultimately that's the pink elephant in the room that we're not really addressing is that **the entire thing is built on theft.**

There's a lot of arguments happening now in terms of, oh, IP, I own this IP. You can't use this IP. But also folks, real people who've been affected by theft and yet there's no protections existing. The political will isn't really there. Maybe a little bit, but it's something that I feel, again, it's more of an existential question.

**Liz Marshall:** Are you a commie? We're so like - people get so brainwashed they don't think. So in the US this whole very effective campaign that if you're not a hardcore capitalist, if you believe in regulation, if you believe in corporate responsibility, if you believe in social democracy, you're a communist.

Unbelievable. What a bunch of bullshit. So yeah, we live in a social democracy. We also live in capitalism. How can we use the levers of capitalism to create change? How can we leverage and foster and uphold the principles of a social democracy to make corporations accountable for their crimes?

**Catherine Warren:** Well said. You know, you mentioned that AI models have largely been trained on scraped and stolen content. And I've been involved in the past year working with a Vancouver company called RAY, which is one of the largest companies that's developed a fair and transparent marketplace for compensating rights holders for AI training content.

However, there's also a carbon cost to this training. So training a single large AI model can consume as much electricity as 120 Canadian homes in a year and emit as much CO2 as 110 cars on the road for a year.

So the question is, even if you're being compensated, even if you agree to participate in this kind of ecosystem, you may not be aware of the carbon cost.

So what is the responsibility for disclosure or self-education around this? And Kevin, I will turn back to you again to ask on the entertainment side what you're doing about the carbon costs of AI filmmaking.

**[[Kevin Friel]]:** Right now, as I suggested earlier, we're a little bit helpless to the factors that we are given in terms of compute.

And I will bang the drum more on incentivizing efficient compute.

What I think is vitally important and perhaps could be a really effective policy procedure and in fact maybe even a tax credit incentive to create a kind of fiscal accountability for efficient compute is **efficient computing reports, and therefore tax credit remuneration based on what kind of models are you using.**

To train. Are they a large behemoth, like OpenAI model? Or are they more of a vastly efficient model? Like some of the ones that ByteDance are putting out, where they run on pennies on the dollar.

Thank goodness there's a bit of a price per token kind of metric that we have out there. 'Cause that kind of gives us a bit of an idea of how much compute is being used for each of these operations. So if there's a policy structure in place that potentially really incentivizes taking - kind of like the tax credit situation that we're used to in film.

And each year, you know, you submit a report on a corporate level, not only are you saving money in real time on compute costs, but you're also being - it's almost like a carbon offset situation. **It's a compute carbon offset.**

I think that could be a very powerful vessel for creating that kind of accountability and sustainability through fiscal responsibility, through policy responsibility.

And I say that as a future projection because the only things that we can really do at the moment is keep compute as local as possible and use smart models locally, have full control of the stack and really look at the reports and using tools like Lionel introduced to us earlier on every sliver of compute that we're doing.

It is time where we start to - you know, instead of just ramming tasks through massive amounts of compute, we look at - we call it **"fix it in pre"** in film if at all possible.

We take a look at the projected compute costs and look at every nip and tuck efficiency. And before long you're saving at least 20%, maybe even 80% if you do it wisely.

So it's creating new paradigms and this is like wild new frontier where everybody's shoving things through on massive compute, on massive models. Taking a step back and saying, hey, we can actually have a lot more control than we thought we had by just being conscientious about it.

**Catherine Warren:** You know, I think about closed media ecosystems that we all participate in. Netflix would be a really good example. And if we look at Netflix, just one streaming company, its annual carbon footprint is about **1.6 million tons of CO2, which is roughly equivalent to all the yearly emissions of the city of Vancouver.**

But now with artificial intelligence, you have things like AI dubbing, you have AI personalization, you have AI optimization. So all of those things ratchet up the carbon footprint and we are all part of that streaming ecosystem.

So we have the power to influence these companies with our pocketbooks, with how we lobby or complain and to encourage them to do this kind of self-monitoring or we will do it for them.

### Audience Questions

**[[Kris Krüg]]:** I do wanna blow this whole conversation up actually though, because I know there's a lot of questions from the audience. And I've got the first one actually.

**I find my relationship with AI non-consensual.**

So you've talked a lot about choosing to be a part of this world, Catherine, or living in this kind of paradigm or whatever, but I'm just doing my best to keep up with the world changing around me or whatever. I'm just trying to figure out where to go from here. It came into my industry and kicked the fucking table over, so I don't feel like I really got a choice.

My best choice is to like host a conversation where I can look at the opportunities and critique the fucking stuff that's broke.

**[[Kevin Friel]]:** And I just want to piggyback off of Kris Krüg's sentiment. And before I became recently quite successful in AI filmmaking, I wasn't working for two years because of the paradigm shifts of Hollywood and also AI to Hollywood.

**[[Kris Krüg]]:** Like spending our inheritance to retool ourselves to have a seat at the table in this new AI filmmaking world or whatever type thing.

**Topo:** Hi guys. I really appreciate all your comments because I think they're tremendously important. I'm coming from the background as a computer scientist. I've been building AI systems since the early nineties.

And Kevin brought a very important point with regards to - **we got lazy as developers** because back in the nineties, optimization was the key because we didn't want to wait three hours for our models to run. So we were looking at minimizing compute power and so on.

But then new processors came and made our life easy, and then we got lazy. I've seen models using algorithms that I developed in the early nineties because they now can run very fast. Back then, we would have to wait three hours for them to be able to generate the output.

So I just wanted to highlight that point because it's super, super important that we don't, we need to be not lazy. We have to be creative in the optimization as software developers. We need to think again on how we are developing these models so that we are not wasting power, that we is not all brute force. That we have to be better at how we do this because our planet is gonna die if we don't take care of all of this.

**[[Kris Krüg]]:** Can you imagine using the most expensive, most smart AI model in the world to make you a recipe?

**Liz Marshall:** I think when Jeffrey Hinton accepted his Nobel Prize, he said, if empathy is not encoded, then we're doomed.

And the paradox there is that AI is the core tool for next gen warfare. It is the core tool for data surveillance and for militarization in all of its forms. Exactly. And it's tested on Palestinians. We know that that's a fact.

So how do we encode empathy when Elon Musk says that empathy is a weakness and Palantir, Peter Thiel, they're all about like dominance.

So for me, in the making of this new documentary, when I explore the intersection or the epicenter of AI data center expansion and water use, all of these issues are contained within. We cannot disentangle the entertainment sector from militarization. It's all connected and it is the core tool for this planet, which is in peril.

**Kay Tigo:** I wanna add a little bit more nuance to the conversation, which is that efficiency is not necessarily the same as sustainability, and those two should not be conflated.

We also can't presume that optimization through AI is synonymous with sustainability. There's nuance there in terms of applying solutions. Again, is it fit for purpose? What is the actual objective? Are we even clear on the objective?

Much like in terms of the various stages of filmmaking, not necessarily all levels of filmmaking should benefit from AI interventions. There are some that's like, you know, it's okay to not have AI applied to that.

And more to the point - I said this in our previous panel - **I just don't quite understand the reason why we're so obsessed with replacing ourselves.**

I don't understand that. The idea that - and to Liz's point earlier - I think there are incredible uses for AI, especially if it's very specific use cases. I think where it becomes ethically problematic is when we're talking about using AI to replace human creativity and labor.

**Liz Marshall:** And to commit genocide.

**Topo:** Thanks to all of you for your thoughts. Every time that there's a panel like this, I get really frustrated because I think we all know what needs to be done, yet it seems like everything is still framed within this big umbrella of capitalism and the discourse of Silicon Valley, of democratization of technology.

And it's a comment more than a question. Just as Liz was saying - even you, as you said, "I'm not a Luddite." **Why not?** There are certain words that, you know - I am a Luddite, I am a socialist. And I think that we need to be able to say these things without fear.

This idea of democratization, I think it's really dangerous. Silicon Valley has sold it to us as something good. I don't - I think there's a difference between democratization and democracy.

Democratization is about participation. And if that's the case, then the Egyptian Pharaoh democratized pyramid building. I won't participate.

And tagging to what Kris Krüg was saying, I feel the same way. I feel like I have no option when they say "everyone can participate." No, everyone has to participate. You have to be on social media. There's no option not to be on LinkedIn in some of these platforms.

So I mean, I guess the comment is an invitation of actually like, let's step outside of those frameworks and maybe go to the root of the problem, which **capitalism is.**

At the end it has to change. When my students ask me, "Hey Topo, what do we have to design? What's the best thing we can design?" I always tell them, **it's not an app, it's not a website, it's none of that. Design a new economic system** because changing the incentives - when we talk about how can we monetize, you know, the incentive of not using this, we are doing - it's insane.

We are talking within a framework that has not served us. Let's not think about how can we monetize one thing or another.

**[[Kris Krüg]]:** Before you guys respond up there - you said, you know, you want people to be able to be more courageous to stand out and say their opinions or whatever, but you also said that we probably all feel the same way. And you just slid that under the radar. You're like, oh, we probably all know what needs to be done. That was your quote. You said, we all know what needs to be done. **What do you think we all know needs to be done?**

**Topo:** Less consumption, not infinite growth. Not everything has to be monetized. And so what needs to be done is a new economic system. This is not a technology problem. It's not even a political problem, it's an economic problem. Value system.

**Sesson Ong:** Thanks so much for everything. I really appreciate the conversation. Talking about regulation, and that's one of the levers that we can do to constrain AI and making sure that we don't over consume.

But I do think we also have to consider the fact that changing human behavior is very difficult. And the reality on the ground is changing that. And to your point, changing the system, that's a really big challenge. I'm an MBA student. We're talking a lot about innovation and entrepreneurship.

Wondering if we can talk about the other lever of **changing the climate crisis through innovation via AI** and what opportunities there are there.

**Catherine Warren:** I mentioned that we launched an ethical artificial intelligence accelerator fund. And the purpose of that was to accelerate startups that were looking at that very problem. So problems of sustainability, inclusion, access, and that kind of thing.

And investing, perhaps in more circularity versus profit and kind of combining interesting economic models with artificial intelligence and using AI as a tool for good.

I'll just highlight one. It's a female founded company called **Reto Labs**. They're Canadian, New Zealand based, and they've created a solution to detoxify social media. So it's used by athletes, leagues, celebrities, politicians that face a lot of online toxicity, which as we know can spill into real world fear and transgressions.

And they're using AI to kind of dominate positive things on feeds and minimize negative things. And it's had a tremendous boost in the mental health of these athletes and others that are using this solution. So that would be an example.

And their business model is very good and fair on top of that. So they're actually practicing what they preach, which has made it difficult for fundraising, which looks at always the hockey stick and - you're an MBA student - these very common metrics.

So we also have to not only change what we make and do, but we have to change the business models that we're using as we go on this journey.

**[[Kris Krüg]]:** Okay, let's talk about changing business models for a second. So, **what role do we wanna play in the AI economy here in British Columbia?**

Do we wanna buy our tokens from San Francisco? Do we wanna produce our tokens in hydro powered indigenous owned data centers in British Columbia? Do we wanna buy LNG powered tokens from Alberta?

So it's like, what role do we want to play in the coming economy? I got kids who live in BC. I want them to have jobs in a future. I want this economy to thrive. I want to send 'em to university. So what part of the economy of the future do we want to play?

**Catherine Warren:** And I just wanna remind everyone here that **Vancouver is a global center for circularity and for the B Corp movement.** So we already have these models that are capitalist busting right here at our doorstep. We have the talent in our city, and we also have a lot of AI savvy in this room.

So maybe twinning those things. We will then find what our secret sauce is, as this unique region.

### Closing Statements

**[[Kris Krüg]]:** How do we use the most insane God-like technology that we have to help us change our own behavior so we become better humans at the same time as using less materials, taking less pictures, using less data, designing better algorithms? How do we do it?

I wanna present that as like a last comment from everybody, kind of like 30 seconds. His question is the same as everyone's in the room.

**Kay Tigo:** I guess to me there's - the premise is problematic for me from the jump. Because when you're talking about being better humans, we can become better humans without technology.

**Go to therapy, deal with your trauma.** Can we get real about that? Like for real? If you don't have enough empathy, then what's wrong with you? Like truly.

**Amanda Silvera:** AI can do those things for us. AI can do amazing things. It's a wonderful tool and there are so many ways that we can use it, but it's just like anything.

**There has to be balance.** We still have to be looking at how we're paying. And I would like to have a home. I would like to have a planet. I would like to have water and food and a future for our kids. That should be just as important as all of these benefits that we get from AI.

We have to look at the perks of having a lovely home to live in, a lovely planet to live on with all the resources that we have. We have to look at that as being just as valuable as everything that AI is bringing us. We don't need to give up one or the other. We just need to find a way to have balance, to be mindful of our consumption in every way. That's all.

**Kay Tigo:** And to your point, Kris Krüg, in terms of folks who make an attempt to heal, the thing about healing is that it's not linear.

It is not linear, it is a lifelong journey. There is no end to it. And what it takes is actually accountability. And that's the main thing that's missing in this whole picture. When we're looking at it, **it's about transparency, it's about accountability, and it boils down to consent. It boils down to control and compensation.**

**Liz Marshall:** My tagline that I mentioned when I first started speaking is the question that I'll pose again - is AI draining this world for another? And I would like to say as my final words that we cannot lose sight or touch with the movement to protect this world, this planet, this water, these trees, this land, this earth, this air and the animals and the people.

And it's an intersectional issue. And we're getting so pulled into these portals and devices and screens and games and ideas and colonizing space and killing people with AI. And it goes on and on.

And I wanna say **let's reinvigorate and not forget the movement, the human based movement to protect this place.**

**[[Kevin Friel]]:** I think there's a really interesting opportunity in a storytelling sense in that these tools are here. There's no way to get around them at the moment. Like it's just here. It's a paradigm that's pervasive.

**There's something very punk rock about having something that's staring you in the face and using that tool in and of itself to tell the stories, to create the change.**

This paradigm is here, this paradox is here, let's use all of our community, all of our voices and all of our talents and convene in this new frontier that is here, whether we want it or not. And it's clear that it's both at the same time.

We are in a time that is many more truths than we ever imagined.

So let's use the tools that are here to tell stories that remind us exactly what we're here for, what we're fighting for - our families, our communities, our global village and probably our galactic village. If we look a little bit further out.

So that's my take on it. **Punk rock. The aesthetic came to life because of the Xerox copying machine.** Xerox was a hideous, terrible company. Like, wow, look at their rap sheet. It's bad. That was just like a drop in the bucket compared to what we may have on our horizon. Let's use these tools to fuck it up y'all.

**Catherine Warren:** And Kris Krüg, you asked what role that we could play here as a community, as a city. I just wanna remind everyone here that Vancouver is a global center for circularity and for the B Corp movement. So we already have these models that are capitalist busting right here at our doorstep. We have the talent in our city, and we also have a lot of AI savvy in this room.

So maybe twinning those things. We will then find what our secret sauce is, as this unique region.

Thank you all so much.

---

## Closing

**[[Kris Krüg]]:** I actually believe in us. I believe in us a lot because we're having these types of conversations, right? Like this is a bunch of different people who don't exactly all think the same way.

Amanda, thank you for being on your first panel and first talk ever for sharing your story. And Kay, thanks for getting more people involved. Catherine, great vision to bring all this together. You broke through my no panels policy.

I really appreciate it and thank you guys for all being a part of this. I'm really just trying to host a conversation that will elevate all of our capabilities so that we can be at the table when these decisions are made and be a part of the future conversation. So welcome to it. Thank you very much.

We got like half an hour left to enjoy ourselves, enjoy some beverages. We have about another half an hour to enjoy ourselves. Please clean up after your neighbor.

The recycles in the back. If you're not on our group chats, ask somebody, "Yo, how do you guys all stay connected all the time?"

---

*Transcript compiled: November 27, 2025*
*Source: vai23.txt raw recording*
*Total runtime: ~4 hours*
